{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64319553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os ## here we will load the env file so you dont need to hardcode your api key\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st ## using streamlit for forntend or web ui\n",
    "load_dotenv()\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")## it will fetch the api key and print it on a streamlit for testing later you can remove\n",
    "groq_api_key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f87e6fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000024540237110>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000024540309310>, model_name='Gemma2-9b-IT', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq    ##creating LLM model and i am using grocks gemma2-9b-it model and chatgroq is the wrapper and ican interact with this model using langchain\n",
    "model=ChatGroq(model=\"Gemma2-9b-IT\",groq_api_key=groq_api_key)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96701be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Ashwini, it's nice to meet you!\\n\\nThat's a fascinating title. As a large language model, I'm always interested in learning more about the work of AI engineers. What kind of projects are you working on these days?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 24, 'total_tokens': 79, 'completion_time': 0.1, 'prompt_time': 0.002211295, 'queue_time': 0.23448644899999999, 'total_time': 0.102211295}, 'model_name': 'Gemma2-9b-IT', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-01367618-96b4-45bf-80d7-52f79b13ae5c-0', usage_metadata={'input_tokens': 24, 'output_tokens': 55, 'total_tokens': 79})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi , My name is Ashwini and i am a Cheif AI Engineer\")])\n",
    "\n",
    "## now ere i am sending a simple message to the LLm model and it will reply like a chatboat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e41733",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6beba42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' here i am sending so many messages to the model this is the conversation between human and ai and this will allow model to understand chat context not just a latest message'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi , My name is Ashwini and i am a Cheif AI Engineer\"),\n",
    "        AIMessage(content=\"It's nice to meet you, Ashwini! \\n\\nThat's a fascinating title. As a Chief AI Engineer, I imagine you're involved in some cutting-edge work. What are you currently working on that you're most excited about?  \\n\\nI'm always eager to learn more about the applications of AI.\\n\"),\n",
    "        HumanMessage(content=\"Hey What's my name and what do i do?\")\n",
    "                  \n",
    "    ]\n",
    ")\n",
    "''' here i am sending so many messages to the model this is the conversation between human and ai and this will allow model to understand chat context not just a latest message'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf45751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]  \n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)  \n",
    "    \n",
    "''' now in this code i am setting up the chat memory so my chatboat can remember what i said in the earlier chat session'''\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8c4a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c1aed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My Name is Ashwini and I am a Chief AI Engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64ae1e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Ashwini, it's nice to meet you! \\n\\nBeing a Chief AI Engineer is a fascinating role. What kind of projects are you currently working on?  I'm always eager to learn more about the cutting edge of AI development.\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37834e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Ashwini.  \\n\\nI remember that from our introduction! üòä  Is there anything else I can help you with?  \\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what's my Name?\")],\n",
    "    config=config\n",
    ")\n",
    "response1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "413c1031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to any personal information about you, including your name. Could you tell me your name? üòä\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1 = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's My Name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fab786bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Sapna, it's nice to meet you! üëã  \\n\\nHow can I help you today? üòÑ  \\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My Name is Sapna?\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7182cc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Ashwini.  I'm happy to remind you! üòÑ  \\n\\nIs there anything else I can help you with today? \\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's My Name?\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ef8517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt =  ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Your are a helpful assistant. Answer all questions to the best of your ability in {language}\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model\n",
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Ashwini\")],\"language\":\"Hindi\"})\n",
    "\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6365647c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Ashwini.  \\n\\nIt's nice to meet you, Ashwini! üëã  Is there anything I can help you with today?\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat5\"}}\n",
    "repsonse=with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"Hi,I am Ashwini\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "repsonse.content\n",
    "\n",
    "repsonse1=with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"What's my name\")],\"language\":\"English\"},\n",
    "    config=config\n",
    ")\n",
    "repsonse1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b06bf5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi! i am bob ', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like choclate ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Whats 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Having fun', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"    \n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you are a good assistant\"),\n",
    "    HumanMessage(content=\"hi! i am bob \"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like choclate ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"Whats 2+2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem\"),\n",
    "    HumanMessage(content=\"Having fun\"),\n",
    "    AIMessage(content=\"yes\"),\n",
    "]\n",
    "trimmer.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83a0d771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You said you like chocolate ice cream!  üç¶üç´  \\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") |trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "\n",
    "response1=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response1.content\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2372d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
    "        metadata={\"source\": \"fish-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
    "        metadata={\"source\": \"bird-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89b3c5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
       " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
       " Document(metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
       " Document(metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.'),\n",
       " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be36e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key.model-\"Llama3-8b-8192\")\n",
    "llm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690b0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
